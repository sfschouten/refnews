{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import json"
      ],
      "metadata": {
        "id": "MHy9mHH89_4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gMp0DCpOX44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f50b8b2-7dce-4f34-a805-e79e37b608da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'refnews'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Total 34 (delta 0), reused 0 (delta 0), pack-reused 34\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/')\n",
        "\n",
        "# clone refnews data repository\n",
        "!git clone https://github.com/sfschouten/refnews.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/')\n",
        "\n",
        "# clone mwep repository (which containst class files necessary to unpickle)\n",
        "!git clone https://github.com/sfschouten/multilingual-wiki-event-pipeline.git mwep -b develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b3CCXRpAQ6c",
        "outputId": "8f723313-d4f5-4c54-8893-7d307f4b8631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mwep'...\n",
            "remote: Enumerating objects: 774, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 774 (delta 22), reused 44 (delta 19), pack-reused 721\u001b[K\n",
            "Receiving objects: 100% (774/774), 84.18 MiB | 18.64 MiB/s, done.\n",
            "Resolving deltas: 100% (504/504), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dependency\n",
        "!pip install rdflib news_please"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbOubOBaA2eW",
        "outputId": "cbc0c741-d271-4ea9-e6f6-c38c44526512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting news_please\n",
            "  Downloading news_please-1.5.22-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib) (4.13.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 573 kB/s \n",
            "\u001b[?25hCollecting Scrapy>=1.1.0\n",
            "  Downloading Scrapy-2.7.0-py2.py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 56.6 MB/s \n",
            "\u001b[?25hCollecting readability-lxml>=0.6.2\n",
            "  Downloading readability_lxml-0.8.1-py3-none-any.whl (20 kB)\n",
            "Collecting plac>=0.9.6\n",
            "  Downloading plac-1.3.5-py2.py3-none-any.whl (22 kB)\n",
            "Collecting warcio>=1.3.3\n",
            "  Downloading warcio-1.7.4-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting ago>=0.0.9\n",
            "  Downloading ago-0.0.95.tar.gz (4.6 kB)\n",
            "Collecting PyMySQL>=0.7.9\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from news_please) (2.8.2)\n",
            "Collecting hjson>=1.5.8\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from news_please) (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from news_please) (4.6.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from news_please) (1.15.0)\n",
            "Collecting cchardet>=2.1.7\n",
            "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
            "\u001b[K     |████████████████████████████████| 263 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting awscli>=1.11.117\n",
            "  Downloading awscli-1.26.1-py3-none-any.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 48.2 MB/s \n",
            "\u001b[?25hCollecting psycopg2-binary>=2.8.4\n",
            "  Downloading psycopg2_binary-2.9.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 38.5 MB/s \n",
            "\u001b[?25hCollecting newspaper3k>=0.2.8\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 56.7 MB/s \n",
            "\u001b[?25hCollecting PyDispatcher>=2.0.5\n",
            "  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)\n",
            "Requirement already satisfied: lxml>=3.3.5 in /usr/local/lib/python3.7/dist-packages (from news_please) (4.9.1)\n",
            "Collecting hurry.filesize>=0.9\n",
            "  Downloading hurry.filesize-0.9.tar.gz (2.8 kB)\n",
            "Collecting dotmap>=1.2.17\n",
            "  Downloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n",
            "Collecting elasticsearch>=2.4\n",
            "  Downloading elasticsearch-8.4.3-py3-none-any.whl (384 kB)\n",
            "\u001b[K     |████████████████████████████████| 384 kB 51.1 MB/s \n",
            "\u001b[?25hCollecting langdetect>=1.0.7\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 41.5 MB/s \n",
            "\u001b[?25hCollecting colorama<0.4.5,>=0.2.5\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting docutils<0.17,>=0.10\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 53.9 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting PyYAML<5.5,>=3.10\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 30.7 MB/s \n",
            "\u001b[?25hCollecting rsa<4.8,>=3.1.2\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting botocore==1.28.1\n",
            "  Downloading botocore-1.28.1-py3-none-any.whl (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 48.7 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 52.0 MB/s \n",
            "\u001b[?25hCollecting elastic-transport<9,>=8\n",
            "  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elastic-transport<9,>=8->elasticsearch>=2.4->news_please) (2022.9.24)\n",
            "Collecting feedparser>=5.2.1\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "Collecting tldextract>=2.0.1\n",
            "  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k>=0.2.8->news_please) (2.23.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k>=0.2.8->news_please) (3.7)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k>=0.2.8->news_please) (7.1.2)\n",
            "Collecting jieba3k>=0.35.1\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting cssselect>=0.9.2\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->news_please) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->news_please) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->news_please) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->news_please) (2022.6.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from readability-lxml>=0.6.2->news_please) (3.0.4)\n",
            "Collecting requests>=2.10.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k>=0.2.8->news_please) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k>=0.2.8->news_please) (2.10)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli>=1.11.117->news_please) (0.4.8)\n",
            "Collecting queuelib>=1.4.2\n",
            "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting parsel>=1.5.0\n",
            "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting pyOpenSSL>=21.0.0\n",
            "  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting Twisted>=18.9.0\n",
            "  Downloading Twisted-22.8.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 47.7 MB/s \n",
            "\u001b[?25hCollecting w3lib>=1.17.0\n",
            "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting zope.interface>=5.1.0\n",
            "  Downloading zope.interface-5.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 53.7 MB/s \n",
            "\u001b[?25hCollecting protego>=0.1.15\n",
            "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting service-identity>=18.1.0\n",
            "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting cryptography>=3.3\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 40.8 MB/s \n",
            "\u001b[?25hCollecting itemloaders>=1.0.1\n",
            "  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n",
            "Collecting itemadapter>=0.1.0\n",
            "  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Scrapy>=1.1.0->news_please) (21.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->Scrapy>=1.1.0->news_please) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->Scrapy>=1.1.0->news_please) (2.21)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news_please) (22.1.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news_please) (0.2.8)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k>=0.2.8->news_please) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->Scrapy>=1.1.0->news_please) (4.1.1)\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting incremental>=21.3.0\n",
            "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting hyperlink>=17.1.1\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib) (3.9.0)\n",
            "Building wheels for collected packages: ago, hurry.filesize, langdetect, tinysegmenter, feedfinder2, jieba3k, PyDispatcher, sgmllib3k\n",
            "  Building wheel for ago (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ago: filename=ago-0.0.95-py3-none-any.whl size=5161 sha256=ef2c274461a029784ca4007b64636b5bba27e83c3210de66360af7a57b61cc03\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/83/c8/b483c665c503205a2afd525f0cb62e7afaa6a858f63a63f6d8\n",
            "  Building wheel for hurry.filesize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hurry.filesize: filename=hurry.filesize-0.9-py3-none-any.whl size=4133 sha256=2f289d9f6a88975d9df53ab14d56d2e1dc544aae6c0cdc091df0e85c665680bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/99/7f/8c88c372b4bd642a731232e63cb89467554f6cea7708574e49\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=3d41672aaf5427b1f0cf9ec1245c34aa84dff6ea5febdb8c30d5bd553cb40089\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13553 sha256=983f9a230f0be3fef441e22847b008d22eaec1150f73ec3ed5bc4d3f183040b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/67/41/faca10fa501ca010be41b49d40360c2959e1c4f09bcbfa37fa\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3357 sha256=e039a590497f730da7de26d539be1a2583a3db443e4c567bbebb5cf5a3aa0ae6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/d4/8f/6e2ca54744c9d7292d88ddb8d42876bcdab5e6d84a21c10346\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398404 sha256=cdf6fbbe4a94628ba93b2476fd54a63591ff89857d6fb8b2c058f975182b6eb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/91/46/3c208287b726df325a5979574324878b679116e4baae1af3c3\n",
            "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11958 sha256=7ee65e244565acfb4867027e6816a484479ec41b4f451b8dcea329a03eea98fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/d6/6a/de198d890277cde60ca3dbebe7ae592d3b381c7d9bb2455f4d\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=b8db0888d865cbcfd460a36f08b4c320de47b1f3235ee7f6a7681f03c8f44a77\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built ago hurry.filesize langdetect tinysegmenter feedfinder2 jieba3k PyDispatcher sgmllib3k\n",
            "Installing collected packages: urllib3, w3lib, requests, jmespath, cssselect, zope.interface, sgmllib3k, requests-file, parsel, itemadapter, incremental, hyperlink, cryptography, constantly, botocore, Automat, Twisted, tldextract, tinysegmenter, service-identity, s3transfer, rsa, queuelib, PyYAML, pyOpenSSL, PyDispatcher, protego, jieba3k, itemloaders, feedparser, feedfinder2, elastic-transport, docutils, colorama, warcio, Scrapy, readability-lxml, PyMySQL, psycopg2-binary, plac, newspaper3k, langdetect, isodate, hurry.filesize, hjson, elasticsearch, dotmap, cchardet, awscli, ago, rdflib, news-please\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "Successfully installed Automat-20.2.0 PyDispatcher-2.0.6 PyMySQL-1.0.2 PyYAML-5.4.1 Scrapy-2.7.0 Twisted-22.8.0 ago-0.0.95 awscli-1.26.1 botocore-1.28.1 cchardet-2.1.7 colorama-0.4.4 constantly-15.1.0 cryptography-38.0.1 cssselect-1.1.0 docutils-0.16 dotmap-1.3.30 elastic-transport-8.4.0 elasticsearch-8.4.3 feedfinder2-0.0.4 feedparser-6.0.10 hjson-3.1.0 hurry.filesize-0.9 hyperlink-21.0.0 incremental-22.10.0 isodate-0.6.1 itemadapter-0.7.0 itemloaders-1.0.6 jieba3k-0.35.1 jmespath-1.0.1 langdetect-1.0.9 news-please-1.5.22 newspaper3k-0.2.8 parsel-1.6.0 plac-1.3.5 protego-0.2.1 psycopg2-binary-2.9.5 pyOpenSSL-22.1.0 queuelib-1.6.2 rdflib-6.2.0 readability-lxml-0.8.1 requests-2.28.1 requests-file-1.5.1 rsa-4.7.2 s3transfer-0.6.0 service-identity-21.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.4.0 urllib3-1.26.12 w3lib-2.0.1 warcio-1.7.4 zope.interface-5.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC = {\n",
        "    'Q1241356_en,pilot.bin':  ('human interest / record and achievement'),\n",
        "    'Q149086_en,pilot.bin':   ('crime, law and justice / crime / homicide'),\n",
        "    'Q167170_en,pilot.bin':   ('sport / sport event'),\n",
        "    'Q18515440_en,pilot.bin': ('sport / sports transaction'),\n",
        "    'Q27318_en,pilot.bin':    ('educaction / educational testing and examinations'),\n",
        "    'Q350604_en,pilot.bin':   ('conflict, war and peace / armed conflict'),\n",
        "    'Q43109_en,pilot.bin':    ('politics / election / referenda'),\n",
        "    'Q45382_en,pilot.bin':    ('conflict, war and peace / coup d\\'etat'),\n",
        "    'Q669262_en,pilot.bin':   ('politics / election / primary election'),\n",
        "    'Q7590_en,pilot.bin':     ('economy, business and finance / strategy and marketing / transport'),\n",
        "    'Q8065_en,pilot.bin':     ('disaster, accident and emergency incident / disaster / natural disaster'),\n",
        "    'Q11822042_en,pilot.bin': ('accident and emergency incident / transportation accident and incident')\n",
        "}\n",
        "\n",
        "DATA_DIR = '/content/refnews/data'\n",
        "\n",
        "collections_by_file = {}\n",
        "total_articles = 0\n",
        "total_incidents = 0\n",
        "\n",
        "# switch to code directory so class files can be found to unpickle\n",
        "os.chdir(os.path.join('/content/mwep'))\n",
        "\n",
        "print('Total number of articles and incidents for which we have URIs.')\n",
        "print(\"file                     |     #articles / #incidents    |  topic\")\n",
        "print('------------------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "for f in os.listdir(DATA_DIR):\n",
        "    if not f.endswith(\".bin\"):\n",
        "        continue\n",
        "    \n",
        "    with open(os.path.join(DATA_DIR, f), 'rb') as pickle_file:\n",
        "        collection = pickle.load(pickle_file)\n",
        "        collections_by_file[f] = collection\n",
        "\n",
        "    nr_incidents = len(collection.incidents)\n",
        "    nr_articles = sum(len(incident.reference_texts) for incident in collection.incidents)\n",
        "\n",
        "    total_articles += nr_articles\n",
        "    total_incidents += nr_incidents\n",
        "\n",
        "    short = f[f.find('Q'):]\n",
        "    topic = TOPIC[short]\n",
        "\n",
        "    print(F\"{short:<23}  |  {nr_articles:<6}  /  {nr_incidents:<5}  =  {nr_articles/nr_incidents:>6.2f}  |  {topic}\")\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------------------------------------')\n",
        "print(F'total                    |  {total_articles:<7} / {total_incidents:<5}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpzxh9pO92t2",
        "outputId": "1baf0a0a-6f3d-4452-d41b-2525e1cd0381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of articles and incidents for which we have URIs.\n",
            "file                     |     #articles / #incidents    |  topic\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "Q669262_en,pilot.bin     |  2612    /  193    =   13.53  |  politics / election / primary election\n",
            "Q8065_en,pilot.bin       |  10900   /  1103   =    9.88  |  disaster, accident and emergency incident / disaster / natural disaster\n",
            "Q11822042_en,pilot.bin   |  16551   /  1822   =    9.08  |  accident and emergency incident / transportation accident and incident\n",
            "Q45382_en,pilot.bin      |  3416    /  339    =   10.08  |  conflict, war and peace / coup d'etat\n",
            "Q43109_en,pilot.bin      |  5627    /  722    =    7.79  |  politics / election / referenda\n",
            "Q350604_en,pilot.bin     |  4155    /  137    =   30.33  |  conflict, war and peace / armed conflict\n",
            "Q167170_en,pilot.bin     |  7188    /  518    =   13.88  |  sport / sport event\n",
            "Q18515440_en,pilot.bin   |  4018    /  196    =   20.50  |  sport / sports transaction\n",
            "Q7590_en,pilot.bin       |  3375    /  206    =   16.38  |  economy, business and finance / strategy and marketing / transport\n",
            "Q1241356_en,pilot.bin    |  15034   /  2352   =    6.39  |  human interest / record and achievement\n",
            "Q149086_en,pilot.bin     |  25123   /  938    =   26.78  |  crime, law and justice / crime / homicide\n",
            "Q27318_en,pilot.bin      |  8168    /  1352   =    6.04  |  educaction / educational testing and examinations\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "total                    |  106167  / 9878 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mwep_settings = json.load(open('/content/mwep/config/mwep_settings.json'))\n",
        "\n",
        "# settings for crawling Wikipedia sources\n",
        "excluded_domains = set(mwep_settings['newsplease']['excluded_domains'])\n",
        "title_required = mwep_settings['newsplease']['title_required']\n",
        "range_start, range_end = mwep_settings['newsplease']['num_chars_range']\n",
        "num_chars_range = range(int(range_start), int(range_end))\n",
        "startswith = mwep_settings['newsplease']['startswith']\n",
        "timeout = mwep_settings['newsplease']['timeout']\n",
        "illegal_substrings = mwep_settings['newsplease']['illegal_substrings']\n",
        "illegal_chars_in_title = mwep_settings['newsplease']['illegal_chars_in_title']"
      ],
      "metadata": {
        "id": "55V60nkuC-iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import crawl_utils\n",
        "import hashlib\n",
        "\n",
        "\n",
        "for f, collection in collections_by_file.items():\n",
        "    \n",
        "    for incident_obj in collection.incidents:\n",
        "        \n",
        "        map = {\n",
        "            ref_text_obj.web_archive_uri: ref_text_obj\n",
        "            for ref_text_obj in incident_obj.reference_texts\n",
        "            if 'Wikipedia source' in ref_text_obj.found_by\n",
        "        }\n",
        "       \n",
        "        primary_url_to_ref_text_obj = crawl_utils.get_ref_text_obj_of_primary_reference_texts(\n",
        "            list(map.keys()),\n",
        "            timeout,\n",
        "            startswith=startswith,\n",
        "            excluded_domains=excluded_domains,\n",
        "            title_required=True,\n",
        "            num_chars_range=num_chars_range,\n",
        "            illegal_substrings=illegal_substrings,\n",
        "            illegal_chars_in_title=illegal_chars_in_title,\n",
        "        )\n",
        "\n",
        "        for wa_url, new_text_obj in primary_url_to_ref_text_obj.items():\n",
        "            old_text_obj = map[wa_url]\n",
        "\n",
        "            old_md5_hash = old_text_obj.content\n",
        "            new_md5_hash = hashlib.md5(new_text_obj.content.encode('utf-8')).hexdigest()\n",
        "\n",
        "            # replace md5 with content\n",
        "            old_text_obj.content = new_text_obj.content\n",
        "\n",
        "            changed = new_md5_hash != old_md5_hash\n",
        "            if changed:\n",
        "                print(f'WARNING: text for {old_text_obj.web_archive_uri} changed')"
      ],
      "metadata": {
        "id": "0hIUdXe1J3-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac25182-87d5-404a-c84f-04b2c8b3eade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/201: : 1it [00:00,  1.67it/s]\n",
            "WARNING: text for http://www.uselectionatlas.org/RESULTS/state.php?year=2004&fips=45&f=1&off=0&elect=1 changed\n",
            "http://web.archive.org/web/202: : 4it [00:12,  3.17s/it]\n",
            "WARNING: text for https://www.britannica.com/event/United-States-presidential-election-of-1972 changed\n",
            "WARNING: text for https://www.nytimes.com/1992/12/07/us/article-says-nixon-schemed-to-tie-foe-to-wallace-attack.html changed\n",
            "WARNING: text for http://www.centerforpolitics.org/crystalball/articles/the-modern-history-of-the-democratic-presidential-primary-1972-2008/ changed\n",
            "http://web.archive.org/web/201: : 2it [00:01,  1.42it/s]\n",
            "WARNING: text for https://books.google.com/books?id=9CZECwAAQBAJ&pg=PA397 changed\n",
            "WARNING: text for https://www.ourcampaigns.com/RaceDetail.html?RaceID=55177&ShowAllMUPoll=Y changed\n",
            "0it [00:00, ?it/s]\n",
            "http://web.archive.org/web/202: : 8it [00:06,  1.16it/s]\n",
            "http://web.archive.org/web/202: : 4it [00:17,  4.29s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:00,  1.76it/s]\n",
            "https://web.archive.org/web/20: : 7it [01:25, 16.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:newsplease.crawler.simple_crawler:connection/timeout error: https://web.archive.org/web/20120402195749/http://www.indystar.com/apps/pbcs.dll/article?AID=/20080513/NEWS0502/805130391 HTTPSConnectionPool(host='web.archive.org', port=443): Read timed out. (read timeout=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://web.archive.org/web/20: : 9it [01:36, 10.69s/it]\n",
            "http://web.archive.org/web/202: : 11it [00:18,  1.70s/it]\n",
            "http://web.archive.org/web/201: : 3it [00:53, 17.72s/it]\n",
            "http://web.archive.org/web/202: : 77it [02:12,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:newsplease.crawler.simple_crawler:connection/timeout error: http://web.archive.org/web/20220101151849/https://www.cnn.com/2016/06/09/politics/president-barack-obama-endorses-hillary-clinton-in-video/index.html HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/202: : 110it [03:16,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dateutil/parser/_parser.py:1212: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
            "  category=UnknownTimezoneWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/202: : 145it [04:24,  1.82s/it]\n",
            "WARNING: text for https://thehill.com/homenews/campaign/360304-brazile-primary-was-not-rigged-because-no-votes-were-overturned changed\n",
            "WARNING: text for https://www.theguardian.com/us-news/live/2016/jun/09/presidential-campaign-bernie-sanders-meet-obama-white-house-clinton-trump changed\n",
            "http://web.archive.org/web/202: : 6it [00:10,  1.70s/it]\n",
            "http://web.archive.org/web/202: : 13it [00:23,  1.78s/it]\n",
            "0it [00:00, ?it/s]\n",
            "https://web.archive.org/web/20: : 2it [00:02,  1.14s/it]\n",
            "http://web.archive.org/web/202: : 3it [00:04,  1.48s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:00,  1.18it/s]\n",
            "http://web.archive.org/web/202: : 3it [00:04,  1.50s/it]\n",
            "https://web.archive.org/web/20: : 1it [00:00,  1.42it/s]\n",
            "http://web.archive.org/web/202: : 6it [00:26,  4.40s/it]\n",
            "WARNING: text for https://www.wsj.com/articles/SB10001424052970203405504576599140469674956 changed\n",
            "http://web.archive.org/web/202: : 16it [08:23, 31.49s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:01,  1.03s/it]\n",
            "http://web.archive.org/web/202: : 23it [00:38,  1.68s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:00,  1.70it/s]\n",
            "https://web.archive.org/web/20: : 6it [01:26, 14.46s/it]\n",
            "0it [00:00, ?it/s]\n",
            "http://web.archive.org/web/202: : 1it [00:01,  1.43s/it]\n",
            "http://web.archive.org/web/202: : 9it [00:25,  2.79s/it]\n",
            "https://web.archive.org/web/20: : 12it [01:46,  5.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:newsplease.crawler.simple_crawler:connection/timeout error: https://web.archive.org/web/20080226113250/http://www.voanews.com/english/2008-02-23-voa3.cfm HTTPSConnectionPool(host='web.archive.org', port=443): Read timed out. (read timeout=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://web.archive.org/web/20: : 15it [05:29, 21.95s/it]\n",
            "http://web.archive.org/web/202: : 21it [00:51,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:newsplease.crawler.simple_crawler:connection/timeout error: http://web.archive.org/web/20210425211658/https://nypost.com/2020/02/06/iowa-democratic-party-chair-ignores-dnc-calls-for-recount-of-caucus/ HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/202: : 24it [01:02,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dateutil/parser/_parser.py:1212: UnknownTimezoneWarning: tzname CST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
            "  category=UnknownTimezoneWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/202: : 27it [01:08,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:newsplease.crawler.simple_crawler:connection/timeout error: http://web.archive.org/web/20210922065844/https://apnews.com/6fa91b6c58290a24655c5ae25cdcb184 HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/202: : 28it [01:16,  4.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:newsplease.crawler.response_decoder:encoding error: UTF-8 / UTF-8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/202: : 85it [03:16,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:newsplease.crawler.simple_crawler:connection/timeout error: http://web.archive.org/web/20210421034554/https://www.theverge.com/2020/2/5/21125449/iowa-recorder-app-democractic-caucus-motherboard-published HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/202: : 90it [03:32,  2.36s/it]\n",
            "0it [00:00, ?it/s]\n",
            "http://web.archive.org/web/202: : 1it [00:01,  1.72s/it]\n",
            "http://web.archive.org/web/201: : 31it [00:51,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 438 bytes but only got 156. Skipping tag 37500\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://web.archive.org/web/20: : 32it [01:16,  8.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:newsplease.crawler.simple_crawler:connection/timeout error: https://web.archive.org/web/20120306113437/http://firstread.msnbc.msn.com/_news/2011/03/09/6226568-2012-searching-for-the-anti-romney HTTPSConnectionPool(host='web.archive.org', port=443): Read timed out. (read timeout=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/201: : 65it [02:41,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dateutil/parser/_parser.py:1212: UnknownTimezoneWarning: tzname ET identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
            "  category=UnknownTimezoneWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "http://web.archive.org/web/202: : 2it [00:13,  6.59s/it]\n",
            "https://web.archive.org/web/20: : 8it [00:11,  1.40s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:01,  1.80s/it]\n",
            "0it [00:00, ?it/s]\n",
            "http://web.archive.org/web/202: : 1it [00:00,  1.71it/s]\n",
            "0it [00:00, ?it/s]\n",
            "http://web.archive.org/web/202: : 16it [00:22,  1.38s/it]\n",
            "0it [00:00, ?it/s]\n",
            "https://web.archive.org/web/20: : 2it [00:03,  1.79s/it]\n",
            "https://web.archive.org/web/20: : 13it [01:50,  8.50s/it]\n",
            "https://web.archive.org/web/20: : 1it [00:53, 53.29s/it]\n",
            "http://web.archive.org/web/202: : 12it [01:37,  8.14s/it]\n",
            "http://web.archive.org/web/202: : 5it [00:07,  1.46s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:00,  1.74it/s]\n",
            "0it [00:00, ?it/s]\n",
            "http://web.archive.org/web/201: : 6it [00:14,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:newsplease.crawler.simple_crawler:connection/timeout error: http://web.archive.org/web/20160609211046/https://www.youtube.com/watch?v=4wVm8WjbVJU HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/202: : 12it [00:34,  2.86s/it]\n",
            "http://web.archive.org/web/202: : 6it [00:12,  2.17s/it]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "http://web.archive.org/web/202: : 2it [00:02,  1.05s/it]\n",
            "http://web.archive.org/web/202: : 3it [00:10,  3.35s/it]\n",
            "https://web.archive.org/web/20: : 3it [00:29,  9.71s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:00,  1.00it/s]\n",
            "http://web.archive.org/web/202: : 6it [00:11,  1.90s/it]\n",
            "http://web.archive.org/web/202: : 4it [00:11,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dateutil/parser/_parser.py:1212: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
            "  category=UnknownTimezoneWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://web.archive.org/web/20: : 13it [00:26,  2.05s/it]\n",
            "0it [00:00, ?it/s]\n",
            "http://web.archive.org/web/202: : 22it [00:51,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:newsplease.crawler.response_decoder:encoding error: UTF-8 / UTF-8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://web.archive.org/web/202: : 29it [01:06,  2.28s/it]\n",
            "WARNING: text for https://www.wsj.com/articles/bernie-sanders-and-hillary-clinton-spar-over-trade-in-midwest-1457051329 changed\n",
            "http://web.archive.org/web/202: : 31it [01:32,  3.00s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:00,  1.71it/s]\n",
            "http://web.archive.org/web/202: : 1it [00:01,  1.19s/it]\n",
            "https://web.archive.org/web/20: : 2it [00:01,  1.21it/s]\n",
            "http://web.archive.org/web/201: : 2it [00:03,  1.65s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:01,  1.98s/it]\n",
            "https://web.archive.org/web/20: : 1it [00:06,  6.28s/it]\n",
            "http://web.archive.org/web/202: : 3it [00:10,  3.42s/it]\n",
            "0it [00:00, ?it/s]\n",
            "http://web.archive.org/web/202: : 5it [00:08,  1.63s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:06,  6.09s/it]\n",
            "https://web.archive.org/web/20: : 1it [00:04,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/newspaper/images.py\", line 118, in fetch_url\n",
            "    p.feed(new_data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 411, in feed\n",
            "    im = Image.open(fp)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2881, in open\n",
            "    im = _open_core(fp, filename, prefix)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2867, in _open_core\n",
            "    im = factory(fp, filename)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 107, in __init__\n",
            "    self._open()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/IcoImagePlugin.py\", line 279, in _open\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/IcoImagePlugin.py\", line 295, in load\n",
            "    im = self.ico.getimage(self.size)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/IcoImagePlugin.py\", line 161, in getimage\n",
            "    return self.frame(self.getentryindex(size, bpp))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/IcoImagePlugin.py\", line 212, in frame\n",
            "    (\"L\", 0, -1),  # 8bpp inverted, unpadded, reversed\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2671, in frombuffer\n",
            "    im = im._new(core.map_buffer(data, size, decoder_name, 0, args))\n",
            "ValueError: buffer is not large enough\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://web.archive.org/web/20: : 17it [02:48,  9.93s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:01,  1.81s/it]\n",
            "http://web.archive.org/web/202: : 1it [00:00,  1.69it/s]\n",
            "http://web.archive.org/web/202: : 4it [01:00, 17.26s/it]"
          ]
        }
      ]
    }
  ]
}